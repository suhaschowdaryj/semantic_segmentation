import sys
import tensorflow as tf
import keras
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from scipy.io import loadmat
import cv2
from skimage.io import imshow
from keras.models import Sequential
from keras.layers import Conv2D,Conv2DTranspose, Cropping2D, Dense, Activation, Dropout, Flatten,MaxPooling2D

import warnings
if not sys.warnoptions:
    warnings.simplefilter("ignore")
    
# Number of classes
n_classes = 21
input_shape = (224, 224, 3)

#fcn-32s architecture

#block1
FCN32 = Sequential()
FCN32.add(Conv2D(64,(3, 3), activation='relu', input_shape=input_shape, padding='same',name = 'conv1_1'))
FCN32.add(Conv2D(64,(3, 3), activation='relu', name = 'conv1_2',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block1_pool'))

#block2
FCN32.add(Conv2D(128,(3, 3), activation='relu', name = 'conv2_1',padding='same'))
FCN32.add(Conv2D(128,(3, 3), activation='relu', name = 'conv2_2',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block2_pool'))

#block3
FCN32.add(Conv2D(256,(3, 3), activation='relu', name = 'conv3_1',padding='same'))
FCN32.add(Conv2D(256,(3, 3), activation='relu', name = 'conv3_2',padding='same'))
FCN32.add(Conv2D(256,(3, 3), activation='relu', name = 'conv3_3',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block3_pool'))

#block4
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv4_1',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv4_2',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv4_3',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block4_pool'))

#block5
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv5_1',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv5_2',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv5_3',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block5_pool'))

#block6
FCN32.add(Conv2D(4096,(7, 7), activation='relu', name = 'fc6'))
FCN32.add(Dropout(0.5))
FCN32.add(Conv2D(4096,(1, 1), activation='relu', name = 'fc7'))
FCN32.add(Dropout(0.5))


# Transformation
FCN32.add(Conv2D(n_classes,(1, 1), activation='linear', kernel_initializer='he_normal', padding='valid', strides=(1, 1), name= 'score_fr'))

#deconvolution
FCN32.add(Conv2DTranspose(n_classes,kernel_size = (64, 64),strides = (32,32), name = 'upsample'))
FCN32.add(Cropping2D(cropping = 16))
FCN32.add(Activation('softmax'))

FCN32.compile(loss="categorical_crossentropy", optimizer='adam', metrics=['accuracy'])

#transfer learning - VGGnet to FCN32

transfer_weights = loadmat('C://Users/jchin/Tensorflow-Segmentation-master/pascal-fcn32s-dag.mat', matlab_compatible=False, struct_as_record=False)
params = transfer_weights['params']

def transfer_learning(input_model):
    layer_names = [l.name for l in input_model.layers]
    for i in range(0, params.shape[1]-1, 2):
        t_name = '_'.join(params[0,i].name[0].split('_')[0:-1])
        if t_name in layer_names:
            kindex = layer_names.index(t_name)
            t_weights = params[0,i].value
            t_bias = params[0,i+1].value
            input_model.layers[kindex].set_weights([t_weights, t_bias[:,0]])
        else:
            print ('not found: ', str(t_name))
            
transfer_learning(FCN32)

# Image directory
image_directory = 'C://Users/jchin/Desktop/image_segmen/VOC2012/JPEGImages/'
segm_image_directory = 'C://Users/jchin/Desktop/image_segmen/VOC2012/SegmentationClass/'
train_set_list = 'C://Users/jchin/Desktop/image_segmen/VOC2012/ImageSets/Segmentation/train.txt'
validation_set_list = 'C://Users/jchin/Desktop/image_segmen/VOC2012/ImageSets/Segmentation/trainval.txt'



# Getting training names in the train.txt
filenames_f = open(trainText, "r")
filenames = []
for line in filenames_f:
    line = line.strip()
    filenames.append(line)
filenames_f.close()   
print('~~Training dataset~~')
# Display number of training names
print('Number of training names:', len(filenames))
# Grab training dataset
images = []
for i in range(len(filenames)):
    images.append(val_image_dir + filenames[i] + '.jpg')
images.sort()
print('Number of test images:', len(images))
# Grab ground truth dataset
segmentations = []
for i in range(len(filenames)):
    segmentations.append(val_target_dir + filenames[i] + '.png')
segmentations.sort()
print('Number of ground truth images:', len(segmentations))
# Getting validation names in the trainval.txt
print('~~Validation dataset~~')
filenames_f = open(validText, "r")
filenamesV = []
for line in filenames_f:
    line = line.strip()
    filenamesV.append(line)
filenames_f.close()
print('Number of validation names:', len(filenamesV))
# Grab validation dataset
vimages = []
for i in range(len(filenamesV)):
    vimages.append(val_image_dir + filenamesV[i] + '.jpg')
vimages.sort()
print('Number of ground truth images for Validation:', len(vimages))


def binarylab(labels, size, nb_class):
    y = np.zeros((size,size, nb_class))
    for i in range(size):
        for j in range(size):
            y[i, j, labels[i][j]] = 1
    return y

def load_data(path, size, label=None):
    img = Image.open(path)
    w, h = img.size
    if w < h:
        if w < size:
            img = img.resize((size, size* h // w))
            w, h = img.size
    else:
        if h < size:
            img = img.resize((size * w // h, size))
            w, h = img.size
    
    img = img.resize((size, size))
    
    if label:
        y = np.array(img, dtype=np.int32)
        mask = y == 255
        y[mask] = 0
        y = binarylab(y, size, 21)
        y = np.expand_dims(y, axis=0)
        return y
    else:
        X = image.img_to_array(img)
        X = np.expand_dims(X, axis=0)
        X = preprocess_input(X)
        return X

def generate_arrays_from_file(names, path_to_train, path_to_target, img_size, nb_class):
    while True:
        for name in names:
            Xpath = path_to_train + "{}.jpg".format(name)
            ypath = path_to_target + "{}.png".format(name)
            X = load_data(Xpath, img_size, label=False)
            y = load_data(ypath, img_size, label=True)
            yield np.array(X) , np.array(y)

X = generate_arrays_from_file(filenames, val_image_dir, val_target_dir, width, classes)
X_get = next(X)
print('Input Shape:', X_get[0].shape)
print('Validation Shape:', X_get[1].shape)

