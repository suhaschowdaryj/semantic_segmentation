import sys
import tensorflow as tf
import keras
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from scipy.io import loadmat
import cv2
from skimage.io import imshow
from keras.models import Sequential
from keras.layers import Conv2D,Conv2DTranspose, Cropping2D, Dense, Activation, Dropout, Flatten,MaxPooling2D

import warnings
if not sys.warnoptions:
    warnings.simplefilter("ignore")
    
# Number of classes
n_classes = 21
input_shape = (224, 224, 3)

#fcn-32s architecture

#block1
FCN32 = Sequential()
FCN32.add(Conv2D(64,(3, 3), activation='relu', input_shape=input_shape, padding='same',name = 'conv1_1'))
FCN32.add(Conv2D(64,(3, 3), activation='relu', name = 'conv1_2',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block1_pool'))

#block2
FCN32.add(Conv2D(128,(3, 3), activation='relu', name = 'conv2_1',padding='same'))
FCN32.add(Conv2D(128,(3, 3), activation='relu', name = 'conv2_2',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block2_pool'))

#block3
FCN32.add(Conv2D(256,(3, 3), activation='relu', name = 'conv3_1',padding='same'))
FCN32.add(Conv2D(256,(3, 3), activation='relu', name = 'conv3_2',padding='same'))
FCN32.add(Conv2D(256,(3, 3), activation='relu', name = 'conv3_3',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block3_pool'))

#block4
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv4_1',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv4_2',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv4_3',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block4_pool'))

#block5
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv5_1',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv5_2',padding='same'))
FCN32.add(Conv2D(512,(3, 3), activation='relu', name = 'conv5_3',padding='same'))
FCN32.add(MaxPooling2D(pool_size=(2,2), strides = (2,2), name = 'block5_pool'))

#block6
FCN32.add(Conv2D(4096,(7, 7), activation='relu', name = 'fc6'))
FCN32.add(Dropout(0.5))
FCN32.add(Conv2D(4096,(1, 1), activation='relu', name = 'fc7'))
FCN32.add(Dropout(0.5))


# Transformation
FCN32.add(Conv2D(n_classes,(1, 1), activation='linear', kernel_initializer='he_normal', padding='valid', strides=(1, 1), name= 'score_fr'))

#deconvolution
FCN32.add(Conv2DTranspose(n_classes,kernel_size = (64, 64),strides = (32,32), name = 'upsample'))
FCN32.add(Cropping2D(cropping = 16))
FCN32.add(Activation('softmax'))

# FCN32.summary()

FCN32.compile(loss="categorical_crossentropy", optimizer='adam', metrics=['accuracy'])

#transfer learning - VGGnet to FCN32

data = loadmat('C://Users/jchin/Tensorflow-Segmentation-master/pascal-fcn32s-dag.mat', matlab_compatible=False, struct_as_record=False)
l = data['layers']
p = data['params']
description = data['meta'][0,0].classes[0,0].description
def copy_mat_to_keras(kmodel):
    kerasnames = [lr.name for lr in kmodel.layers]
    for i in range(0, p.shape[1]-1, 2):
        matname = '_'.join(p[0,i].name[0].split('_')[0:-1])
        if matname in kerasnames:
            kindex = kerasnames.index(matname)
            l_weights = p[0,i].value
            l_bias = p[0,i+1].value
            kmodel.layers[kindex].set_weights([l_weights, l_bias[:,0]])
        else:
            print ('not found: ', str(matname)
)
            
copy_mat_to_keras(FCN32)


# Directory needed
val_image_dir = 'C://Users/jchin/Desktop/image_segmen/VOC2012/JPEGImages/'
val_target_dir = 'C://Users/jchin/Desktop/image_segmen/VOC2012/SegmentationClass/'
trainText = 'C://Users/jchin/Desktop/image_segmen/VOC2012/ImageSets/Segmentation/train.txt'
validText = 'C://Users/jchin/Desktop/image_segmen/VOC2012/ImageSets/Segmentation/trainval.txt'


# Getting training names in the train.txt
filenames_f = open(trainText, "r")
filenames = []
for line in filenames_f:
    line = line.strip()
    filenames.append(line)
filenames_f.close()   
print('~~Training dataset~~')
# Display number of training names
print('Number of training names:', len(filenames))
# Grab training dataset
images = []
for i in range(len(filenames)):
    images.append(val_image_dir + filenames[i] + '.jpg')
images.sort()
print('Number of test images:', len(images))
# Grab ground truth dataset
segmentations = []
for i in range(len(filenames)):
    segmentations.append(val_target_dir + filenames[i] + '.png')
segmentations.sort()
print('Number of ground truth images:', len(segmentations))
# Getting validation names in the trainval.txt
print('~~Validation dataset~~')
filenames_f = open(validText, "r")
filenamesV = []
for line in filenames_f:
    line = line.strip()
    filenamesV.append(line)
filenames_f.close()
print('Number of validation names:', len(filenamesV))
# Grab validation dataset
vimages = []
for i in range(len(filenamesV)):
    vimages.append(val_image_dir + filenamesV[i] + '.jpg')
vimages.sort()
print('Number of ground truth images for Validation:', len(vimages))


def binarylab(labels, size, nb_class):
    y = np.zeros((size,size, nb_class))
    for i in range(size):
        for j in range(size):
            y[i, j, labels[i][j]] = 1
    return y

def load_data(path, size, label=None):
    img = Image.open(path)
    w, h = img.size
    if w < h:
        if w < size:
            img = img.resize((size, size* h // w))
            w, h = img.size
    else:
        if h < size:
            img = img.resize((size * w // h, size))
            w, h = img.size
    
    img = img.resize((size, size))
    
    if label:
        y = np.array(img, dtype=np.int32)
        mask = y == 255
        y[mask] = 0
        y = binarylab(y, size, 21)
        y = np.expand_dims(y, axis=0)
        return y
    else:
        X = image.img_to_array(img)
        X = np.expand_dims(X, axis=0)
        X = preprocess_input(X)
        return X

def generate_arrays_from_file(names, path_to_train, path_to_target, img_size, nb_class):
    while True:
        for name in names:
            Xpath = path_to_train + "{}.jpg".format(name)
            ypath = path_to_target + "{}.png".format(name)
            X = load_data(Xpath, img_size, label=False)
            y = load_data(ypath, img_size, label=True)
            yield np.array(X) , np.array(y)

X = generate_arrays_from_file(filenames, val_image_dir, val_target_dir, width, classes)
X_get = next(X)
print('Input Shape:', X_get[0].shape)
print('Validation Shape:', X_get[1].shape)



def prepareim(im):
    im[:,:,0] -= 103.939
    im[:,:,1] -= 116.779
    im[:,:,2] -= 123.68
    im = np.expand_dims(im, axis=0)
    return im
    
    
subset = filenames[0: len(filenames)]
S = np.random.choice(len(filenames))
S = 25

# Imput Image
inputImg = cv2.imread(images[S])

inputImg1 = Image.open('C://Users/jchin/Desktop/image_segmen/VOC2012/JPEGImages/2007_002088.jpg')
image = inputImg1.resize((224,224))

inputImg = np.frombuffer(image.tobytes(), dtype=np.uint8).reshape((224,224,3))
inputImgP = inputImg.astype('float64')
inputImgP = prepareim(inputImgP)
preds = FCN32.predict(inputImgP)

imclass = np.argmax(preds, axis=3)[0,:,:]
print(imclass.shape)
plt.figure(figsize = (15, 7))
plt.subplot(1,3,1)
plt.imshow( np.asarray(inputImg) )
plt.subplot(1,3,2)
plt.imshow( imclass )
plt.subplot(1,3,3)
plt.imshow( np.asarray(inputImg) )
masked_imclass = np.ma.masked_where(imclass == 0, imclass)
plt.imshow( imclass, alpha=0.5 )
plt.imshow( masked_imclass, alpha=0.5 )

plt.show()



